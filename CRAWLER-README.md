# Playwright Crawler for PreIPO SIP Application

Comprehensive automated testing crawler that visits every route in your Next.js + Laravel application, detects errors, clicks links, and generates detailed reports.

## Features

âœ… **3 Test Modes**: PUBLIC, USER, ADMIN
âœ… **Automatic Login**: Authenticates as user/admin before testing protected routes
âœ… **Error Detection**: 404, 500, missing components, infinite redirects
âœ… **Link Testing**: Clicks every `<a>` tag on each page
âœ… **Dynamic Route Handling**: Automatically resolves dynamic parameters
âœ… **Comprehensive Reports**: JSON and CSV output with screenshots
âœ… **Console Error Tracking**: Captures JavaScript errors
âœ… **Redirect Chain Tracking**: Monitors redirect loops
âœ… **Response Time Monitoring**: Measures page load performance

---

## Prerequisites

- Node.js 18+ and npm/yarn
- Next.js frontend running on http://localhost:3000
- Laravel backend running on http://localhost:8000
- Valid user and admin credentials

---

## Installation

### Step 1: Install Dependencies

Since this is a crawler script in your existing repo, install dependencies:

```bash
# Install Node dependencies from crawler-package.json
npm install @playwright/test playwright json2csv dotenv ts-node typescript @types/node
```

Or copy the dependencies from `crawler-package.json` to your main `package.json`.

### Step 2: Install Playwright Browsers

```bash
npx playwright install chromium
```

### Step 3: Configure Environment Variables

Create a `.env.crawler` file:

```bash
cp .env.crawler.example .env.crawler
```

Edit `.env.crawler` with your actual credentials:

```env
FRONTEND_URL=http://localhost:3000
BACKEND_URL=http://localhost:8000

USER_EMAIL=testuser@example.com
USER_PASSWORD=your_user_password

ADMIN_EMAIL=admin@example.com
ADMIN_PASSWORD=your_admin_password

HEADLESS=true
SCREENSHOTS=false
```

---

## Usage

### Basic Usage (All Modes)

```bash
# Load .env.crawler and run crawler
export $(cat .env.crawler | xargs) && ts-node playwright-crawler.ts
```

### Run with Screenshots Enabled

```bash
export $(cat .env.crawler | xargs) && SCREENSHOTS=true ts-node playwright-crawler.ts
```

### Run in Non-Headless Mode (See Browser)

```bash
export $(cat .env.crawler | xargs) && HEADLESS=false ts-node playwright-crawler.ts
```

### Run with Full Logging

```bash
export $(cat .env.crawler | xargs) && SCREENSHOTS=true HEADLESS=false ts-node playwright-crawler.ts
```

---

## NPM Scripts

Add these scripts to your `package.json`:

```json
{
  "scripts": {
    "crawler": "export $(cat .env.crawler | xargs) && ts-node playwright-crawler.ts",
    "crawler:headless": "export $(cat .env.crawler | xargs) && HEADLESS=true ts-node playwright-crawler.ts",
    "crawler:screenshots": "export $(cat .env.crawler | xargs) && SCREENSHOTS=true ts-node playwright-crawler.ts",
    "crawler:full": "export $(cat .env.crawler | xargs) && SCREENSHOTS=true HEADLESS=false ts-node playwright-crawler.ts"
  }
}
```

Then run:

```bash
npm run crawler
npm run crawler:screenshots
npm run crawler:full
```

---

## How It Works

### 1. **Route Loading**
   - Reads `route-map.json` generated by the route extraction script
   - Categorizes routes into PUBLIC, USER, and ADMIN

### 2. **PUBLIC Mode**
   - Tests all public routes without authentication
   - Homepage, login, signup, blog, products, FAQs, etc.

### 3. **USER Mode**
   - Logs in with USER credentials
   - Tests all authenticated user routes
   - Dashboard, profile, wallet, portfolio, support, etc.

### 4. **ADMIN Mode**
   - Logs in with ADMIN credentials
   - Tests all admin panel routes
   - User management, KYC queue, payments, settings, etc.

### 5. **Error Detection**
   - **404**: Detects "not found" text in page content
   - **500**: Detects "server error" or error pages
   - **Redirect Loops**: Tracks redirect chains, fails after 5 redirects
   - **Missing Components**: Checks if page has actual content
   - **React Errors**: Detects Next.js error overlays

### 6. **Link Clicking**
   - Finds all `<a href>` tags on each page
   - Opens first 20 internal links
   - Tests each link in a new page context
   - Counts successful clicks

### 7. **Report Generation**
   - **JSON Report**: Complete test results with all details
   - **CSV Report**: Spreadsheet-friendly format for analysis
   - **Summary Report**: High-level statistics
   - **Screenshots**: Captured for pages with errors (if enabled)

---

## Reports Output

All reports are saved to `/reports` directory:

```
reports/
â”œâ”€â”€ crawler-report-2025-11-25T10-30-00.json
â”œâ”€â”€ crawler-report-2025-11-25T10-30-00.csv
â”œâ”€â”€ crawler-summary-2025-11-25T10-30-00.json
â””â”€â”€ screenshots/
    â”œâ”€â”€ PUBLIC_login_error_1732534200000.png
    â”œâ”€â”€ USER_dashboard_error_1732534201000.png
    â””â”€â”€ ADMIN_settings_error_1732534202000.png
```

### JSON Report Format

```json
[
  {
    "url": "http://localhost:3000/dashboard",
    "status": 200,
    "errorType": null,
    "responseTime": 1250,
    "redirectChain": [],
    "missingComponents": [],
    "clickedLinks": 15,
    "timestamp": "2025-11-25T10:30:00.000Z",
    "mode": "USER",
    "screenshotPath": null
  }
]
```

### CSV Report Format

```csv
URL,STATUS,ERROR_TYPE,RESPONSE_TIME_MS,REDIRECT_COUNT,MISSING_COMPONENTS,CLICKED_LINKS,MODE,TIMESTAMP,SCREENSHOT
http://localhost:3000/dashboard,200,NONE,1250,0,,15,USER,2025-11-25T10:30:00.000Z,
http://localhost:3000/admin/users,404,404_NOT_FOUND,850,0,,0,ADMIN,2025-11-25T10:30:01.000Z,/reports/screenshots/...
```

### Summary Report

```json
{
  "totalTests": 102,
  "successful": 95,
  "errors": 7,
  "notFound": 3,
  "serverErrors": 2,
  "redirectLoops": 1,
  "avgResponseTime": 1150,
  "byMode": {
    "PUBLIC": 21,
    "USER": 41,
    "ADMIN": 40
  }
}
```

---

## Dynamic Route Handling

The crawler automatically resolves dynamic routes like:

- `/blog/[slug]` â†’ `/blog/test-slug-1732534200`
- `/users/[userId]` â†’ `/users/1`
- `/api/v1/products/{slug}` â†’ `/api/v1/products/test-product`

Dynamic resolvers are defined in the script:

```typescript
const dynamicRouteResolvers: Record<string, () => string> = {
  '[slug]': () => 'test-slug-' + Date.now(),
  '[id]': () => '1',
  '[userId]': () => '1',
  // ... more resolvers
};
```

### Customizing Dynamic Routes

To use real IDs from your database, modify the resolvers:

```typescript
'[userId]': () => '123', // Use a real user ID
'[slug]': () => 'real-blog-post', // Use a real slug
```

---

## Error Types

| Error Type | Description |
|------------|-------------|
| `404_NOT_FOUND` | Page shows 404 or "not found" text |
| `500_SERVER_ERROR` | Page shows 500 or server error |
| `INFINITE_REDIRECT` | More than 5 redirects detected |
| `REACT_ERROR` | Next.js error overlay or unhandled error |
| `MISSING_COMPONENTS` | Page has no content or very few elements |
| `UNKNOWN_ERROR` | Unexpected error during navigation |

---

## Configuration Options

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `FRONTEND_URL` | `http://localhost:3000` | Next.js frontend URL |
| `BACKEND_URL` | `http://localhost:8000` | Laravel backend URL |
| `USER_EMAIL` | - | User login email |
| `USER_PASSWORD` | - | User login password |
| `ADMIN_EMAIL` | - | Admin login email |
| `ADMIN_PASSWORD` | - | Admin login password |
| `HEADLESS` | `true` | Run browser in headless mode |
| `SCREENSHOTS` | `false` | Take screenshots on errors |
| `TIMEOUT` | `30000` | Page load timeout (ms) |
| `MAX_REDIRECTS` | `5` | Max redirects before error |

---

## Troubleshooting

### Issue: Login Fails

**Solution**: Verify credentials in `.env.crawler` and ensure the login form selectors match your application:

```typescript
await page.fill('input[type="email"], input[name="email"]', email);
await page.fill('input[type="password"], input[name="password"]', password);
```

### Issue: Too Many Routes to Test

**Solution**: Limit routes by filtering in the script:

```typescript
const frontendRoutes = routes
  .flatMap((category) => category.routes)
  .filter((route) => route.type === 'page' && route.path)
  .slice(0, 20) // Test only first 20 routes
  .map((route) => route.path!);
```

### Issue: Screenshots Not Saving

**Solution**: Ensure `SCREENSHOTS=true` and `/reports/screenshots` directory is writable.

### Issue: Dynamic Routes Fail

**Solution**: Update `dynamicRouteResolvers` with real IDs from your database.

---

## Advanced Usage

### Test Only Specific Routes

Modify the script to filter specific categories:

```typescript
// Test only admin settings routes
const frontendRoutes = routes
  .filter((category) => category.category.includes('Settings'))
  .flatMap((category) => category.routes)
  .map((route) => route.path!);
```

### Add Custom Error Detection

Add your own error detection logic:

```typescript
// Check for specific error messages
const hasCustomError = await page.evaluate(() => {
  return document.body.innerText.includes('Your custom error text');
});

if (hasCustomError) {
  return {
    status: 'ERROR',
    errorType: 'CUSTOM_ERROR',
    missingComponents: [],
  };
}
```

### Test API Endpoints

Extend the script to test backend API routes:

```typescript
import axios from 'axios';

async function testApiEndpoint(url: string, method: string, token: string) {
  try {
    const response = await axios({
      method,
      url: `${config.backendUrl}${url}`,
      headers: { Authorization: `Bearer ${token}` },
    });
    return { status: response.status, error: null };
  } catch (error: any) {
    return { status: error.response?.status || 'ERROR', error: error.message };
  }
}
```

---

## CI/CD Integration

### GitHub Actions Example

```yaml
name: Crawler Tests

on:
  push:
    branches: [main]
  schedule:
    - cron: '0 2 * * *' # Run daily at 2am

jobs:
  crawler:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-node@v3
        with:
          node-version: 18

      - name: Install dependencies
        run: npm install

      - name: Install Playwright
        run: npx playwright install chromium

      - name: Start services
        run: |
          docker-compose up -d
          sleep 10

      - name: Run crawler
        env:
          USER_EMAIL: ${{ secrets.USER_EMAIL }}
          USER_PASSWORD: ${{ secrets.USER_PASSWORD }}
          ADMIN_EMAIL: ${{ secrets.ADMIN_EMAIL }}
          ADMIN_PASSWORD: ${{ secrets.ADMIN_PASSWORD }}
        run: npm run crawler

      - name: Upload reports
        uses: actions/upload-artifact@v3
        with:
          name: crawler-reports
          path: reports/
```

---

## Performance Tips

1. **Limit Link Clicking**: Reduce from 20 to 5 for faster runs
2. **Skip Screenshots**: Disable unless debugging
3. **Run in Headless**: Always use headless mode in CI/CD
4. **Parallel Testing**: Split routes across multiple workers
5. **Cache Results**: Store successful routes to skip on next run

---

## Contributing

To improve the crawler:

1. Add more error detection patterns
2. Improve dynamic route resolvers
3. Add API endpoint testing
4. Add performance metrics (LCP, FCP, etc.)
5. Add accessibility checks (ARIA, contrast, etc.)

---

## License

MIT

---

## Support

For issues or questions, open an issue in the repository.

Happy Testing! ðŸš€
